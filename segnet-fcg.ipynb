{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prepare dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6736, 8515, 3)\r\n",
      "374\r\n",
      "(2618, 1, 32, 32) (51238, 1, 32, 32)\r\n",
      "(2618, 32, 32, 3) (51238, 32, 32, 3)\r\n",
      "(2618, 1, 32, 32) (51238, 1, 32, 32)\r\n"
     ]
    }
   ],
   "source": [
    "!python dataset_preprocess.py --patch_size 32 --step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**net components and net structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*components*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        n_filters,\n",
    "        k_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        bias=True,\n",
    "        dilation=1,\n",
    "        is_batchnorm=True,\n",
    "    ):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "\n",
    "        conv_mod = nn.Conv2d(\n",
    "            int(in_channels),\n",
    "            int(n_filters),\n",
    "            kernel_size=k_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            bias=bias,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "\n",
    "        if is_batchnorm:\n",
    "            self.cb_unit = nn.Sequential(conv_mod, nn.BatchNorm2d(int(n_filters)))\n",
    "        else:\n",
    "            self.cb_unit = nn.Sequential(conv_mod)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.cb_unit(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class conv2DGroupNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, n_filters, k_size, stride, padding, bias=True, dilation=1, n_groups=16\n",
    "    ):\n",
    "        super(conv2DGroupNorm, self).__init__()\n",
    "\n",
    "        conv_mod = nn.Conv2d(\n",
    "            int(in_channels),\n",
    "            int(n_filters),\n",
    "            kernel_size=k_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            bias=bias,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "\n",
    "        self.cg_unit = nn.Sequential(conv_mod, nn.GroupNorm(n_groups, int(n_filters)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.cg_unit(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class deconv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, n_filters, k_size, stride, padding, bias=True):\n",
    "        super(deconv2DBatchNorm, self).__init__()\n",
    "\n",
    "        self.dcb_unit = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                int(in_channels),\n",
    "                int(n_filters),\n",
    "                kernel_size=k_size,\n",
    "                padding=padding,\n",
    "                stride=stride,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.BatchNorm2d(int(n_filters)),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dcb_unit(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        n_filters,\n",
    "        k_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        bias=True,\n",
    "        dilation=1,\n",
    "        is_batchnorm=True,\n",
    "    ):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "\n",
    "        conv_mod = nn.Conv2d(\n",
    "            int(in_channels),\n",
    "            int(n_filters),\n",
    "            kernel_size=k_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            bias=bias,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "\n",
    "        if is_batchnorm:\n",
    "            self.cbr_unit = nn.Sequential(\n",
    "                conv_mod, nn.BatchNorm2d(int(n_filters)), nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.cbr_unit = nn.Sequential(conv_mod, nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.cbr_unit(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class conv2DGroupNormRelu(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, n_filters, k_size, stride, padding, bias=True, dilation=1, n_groups=16\n",
    "    ):\n",
    "        super(conv2DGroupNormRelu, self).__init__()\n",
    "\n",
    "        conv_mod = nn.Conv2d(\n",
    "            int(in_channels),\n",
    "            int(n_filters),\n",
    "            kernel_size=k_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            bias=bias,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "\n",
    "        self.cgr_unit = nn.Sequential(\n",
    "            conv_mod, nn.GroupNorm(n_groups, int(n_filters)), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.cgr_unit(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class deconv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, n_filters, k_size, stride, padding, bias=True):\n",
    "        super(deconv2DBatchNormRelu, self).__init__()\n",
    "\n",
    "        self.dcbr_unit = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                int(in_channels),\n",
    "                int(n_filters),\n",
    "                kernel_size=k_size,\n",
    "                padding=padding,\n",
    "                stride=stride,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.BatchNorm2d(int(n_filters)),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dcbr_unit(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class segnetDown2(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(segnetDown2, self).__init__()\n",
    "        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n",
    "        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n",
    "        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        unpooled_shape = outputs.size()\n",
    "        outputs, indices = self.maxpool_with_argmax(outputs)\n",
    "        return outputs, indices, unpooled_shape\n",
    "\n",
    "\n",
    "class segnetDown3(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(segnetDown3, self).__init__()\n",
    "        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n",
    "        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n",
    "        self.conv3 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n",
    "        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.conv3(outputs)\n",
    "        unpooled_shape = outputs.size()\n",
    "        outputs, indices = self.maxpool_with_argmax(outputs)\n",
    "        return outputs, indices, unpooled_shape\n",
    "\n",
    "\n",
    "class segnetUp2(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(segnetUp2, self).__init__()\n",
    "        self.unpool = nn.MaxUnpool2d(2, 2)\n",
    "        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n",
    "        self.conv2 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n",
    "\n",
    "    def forward(self, inputs, indices, output_shape):\n",
    "        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n",
    "        outputs = self.conv1(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class segnetUp3(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(segnetUp3, self).__init__()\n",
    "        self.unpool = nn.MaxUnpool2d(2, 2)\n",
    "        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n",
    "        self.conv2 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n",
    "        self.conv3 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n",
    "\n",
    "    def forward(self, inputs, indices, output_shape):\n",
    "        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n",
    "        outputs = self.conv1(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.conv3(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*structure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "#from netutils import segnetDown2, segnetDown3, segnetUp2, segnetUp3\n",
    "\n",
    "\n",
    "class segnet(nn.Module):\n",
    "    def __init__(self, n_classes=21, in_channels=3, is_unpooling=True):\n",
    "        super(segnet, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.is_unpooling = is_unpooling\n",
    "        self.down1 = segnetDown2(self.in_channels, 64)\n",
    "        self.down2 = segnetDown2(64, 128)\n",
    "        self.down3 = segnetDown3(128, 256)\n",
    "        self.down4 = segnetDown3(256, 512)\n",
    "        self.down5 = segnetDown3(512, 512) # not used\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = True\n",
    "        self.up5 = segnetUp3(512, 512) # not used\n",
    "        self.up4 = segnetUp3(512, 256)\n",
    "        self.up3 = segnetUp3(256, 128)\n",
    "        self.up2 = segnetUp2(128, 64)\n",
    "        self.up1 = segnetUp2(64, n_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        down1, indices_1, unpool_shape1 = self.down1(inputs)\n",
    "        down2, indices_2, unpool_shape2 = self.down2(down1)\n",
    "        down3, indices_3, unpool_shape3 = self.down3(down2)\n",
    "        down4, indices_4, unpool_shape4 = self.down4(down3)\n",
    "        down5, indices_5, unpool_shape5 = self.down5(down4)\n",
    "        \n",
    "        up5 = self.up5(down5, indices_5, unpool_shape5) # not used\n",
    "        up4 = self.up4(up5, indices_4, unpool_shape4)\n",
    "        up3 = self.up3(up4, indices_3, unpool_shape3)\n",
    "        up2 = self.up2(up3, indices_2, unpool_shape2)\n",
    "        up1 = self.up1(up2, indices_1, unpool_shape1)\n",
    "        return up1\n",
    "    def init_vgg16_params(self, vgg16):\n",
    "        blocks = [self.down1, self.down2, self.down3, self.down4, self.down5]\n",
    "\n",
    "        features = list(vgg16.features.children())\n",
    "\n",
    "        vgg_layers = []\n",
    "        for _layer in features:\n",
    "            if isinstance(_layer, nn.Conv2d):\n",
    "                vgg_layers.append(_layer)\n",
    "\n",
    "        merged_layers = []\n",
    "        for idx, conv_block in enumerate(blocks):\n",
    "            if idx < 2:\n",
    "                units = [conv_block.conv1.cbr_unit, conv_block.conv2.cbr_unit]\n",
    "            else:\n",
    "                units = [\n",
    "                    conv_block.conv1.cbr_unit,\n",
    "                    conv_block.conv2.cbr_unit,\n",
    "                    conv_block.conv3.cbr_unit,\n",
    "                ]\n",
    "            for _unit in units:\n",
    "                for _layer in _unit:\n",
    "                    if isinstance(_layer, nn.Conv2d):\n",
    "                        merged_layers.append(_layer)\n",
    "\n",
    "        assert len(vgg_layers) == len(merged_layers)\n",
    "\n",
    "        for l1, l2 in zip(vgg_layers, merged_layers):\n",
    "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                assert l1.weight.size() == l2.weight.size()\n",
    "                assert l1.bias.size() == l2.bias.size()\n",
    "                l2.weight.data = l1.weight.data\n",
    "                l2.bias.data = l1.bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "import sklearn.metrics as metrics\n",
    "# from netutils import *\n",
    "# from segnet import *\n",
    "# from mytictoc import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "patch_size = 32\n",
    "class config():\n",
    "    patch_size = 32\n",
    "    step = 32\n",
    "    lr = 0.05\n",
    "    weight_decay = 0.0005\n",
    "    num_class = 5\n",
    "    epoch = 80\n",
    "    batch_size = 500\n",
    "    momentum = 0.9\n",
    "opt = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /tmp/.torch/models/vgg16-397923af.pth\n",
      "100%|██████████| 553433881/553433881 [00:10<00:00, 52568526.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epoch num is 80\n",
      "current epoch:0;  train loss:1.5578383;  train acc:0.2682794348075565;  eval loss:1.5316556;  eval acc:0.5639471338892962\n",
      "validation loss decreases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type segnet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type segnetDown2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type conv2DBatchNormRelu. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type segnetDown3. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type segnetUp3. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type segnetUp2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch:1;  train loss:1.3150523;  train acc:0.6107220493467514;  eval loss:1.3684666;  eval acc:0.5664797585227271\n",
      "validation loss decreases...\n",
      "current epoch:2;  train loss:1.166938;  train acc:0.6317656360346046;  eval loss:1.2843099;  eval acc:0.5696498464992668\n",
      "validation loss decreases...\n",
      "current epoch:3;  train loss:1.0126544;  train acc:0.7071543299788136;  eval loss:1.2919371;  eval acc:0.5725943456744867\n",
      "1epochs of increasing val loss\n",
      "current epoch:4;  train loss:0.9453277;  train acc:0.7151785564530367;  eval loss:1.3342907;  eval acc:0.569554011638563\n",
      "2epochs of increasing val loss\n",
      "current epoch:5;  train loss:0.8912663;  train acc:0.7267237707450565;  eval loss:1.3511481;  eval acc:0.5649490927419355\n",
      "3epochs of increasing val loss\n",
      "current epoch:6;  train loss:0.87136817;  train acc:0.7222760527012713;  eval loss:1.208771;  eval acc:0.5676413123167156\n",
      "validation loss decreases...\n",
      "current epoch:7;  train loss:0.8330962;  train acc:0.7305094842425848;  eval loss:1.1639537;  eval acc:0.5817318262005132\n",
      "validation loss decreases...\n",
      "current epoch:8;  train loss:0.81455106;  train acc:0.7298245553054379;  eval loss:0.8788954;  eval acc:0.7367694109695747\n",
      "validation loss decreases...\n",
      "current epoch:9;  train loss:0.78165334;  train acc:0.732200173243291;  eval loss:0.87362885;  eval acc:0.7409766140487537\n",
      "validation loss decreases...\n",
      "current epoch:10;  train loss:0.7942192;  train acc:0.7249127604166667;  eval loss:1.2693404;  eval acc:0.6314556050678153\n",
      "1epochs of increasing val loss\n",
      "current epoch:11;  train loss:0.75000113;  train acc:0.7261097005208333;  eval loss:1.0207355;  eval acc:0.7408039429068914\n",
      "2epochs of increasing val loss\n",
      "current epoch:12;  train loss:0.7172096;  train acc:0.7283533776924435;  eval loss:0.8032504;  eval acc:0.746082592558651\n",
      "validation loss decreases...\n",
      "current epoch:13;  train loss:0.6758148;  train acc:0.7400496115819207;  eval loss:0.79074556;  eval acc:0.7760234718658358\n",
      "validation loss decreases...\n",
      "current epoch:14;  train loss:0.60182005;  train acc:0.7895126677259888;  eval loss:0.79860187;  eval acc:0.6983577025293255\n",
      "1epochs of increasing val loss\n",
      "current epoch:15;  train loss:0.566704;  train acc:0.8045285079007768;  eval loss:0.8859371;  eval acc:0.6504278260172287\n",
      "2epochs of increasing val loss\n",
      "current epoch:16;  train loss:0.4852452;  train acc:0.8562703809145481;  eval loss:0.6880293;  eval acc:0.7728737800128299\n",
      "validation loss decreases...\n",
      "current epoch:17;  train loss:0.39829087;  train acc:0.8910222236935028;  eval loss:0.7118574;  eval acc:0.7677414772727272\n",
      "1epochs of increasing val loss\n",
      "current epoch:18;  train loss:0.36112866;  train acc:0.9018679599223164;  eval loss:0.6100347;  eval acc:0.8185746368676685\n",
      "validation loss decreases...\n",
      "current epoch:19;  train loss:0.31782773;  train acc:0.9139150114759887;  eval loss:0.6186722;  eval acc:0.8125308719758063\n",
      "1epochs of increasing val loss\n",
      "current epoch:20;  train loss:0.29568082;  train acc:0.9220729939088984;  eval loss:0.67543215;  eval acc:0.7861784560575512\n",
      "2epochs of increasing val loss\n",
      "current epoch:21;  train loss:0.2762448;  train acc:0.9275360886740819;  eval loss:0.6907039;  eval acc:0.7783827838618035\n",
      "3epochs of increasing val loss\n",
      "current epoch:22;  train loss:0.2704338;  train acc:0.9274221563824153;  eval loss:0.6004376;  eval acc:0.8099846499266863\n",
      "validation loss decreases...\n",
      "current epoch:23;  train loss:0.27896076;  train acc:0.9229943171786723;  eval loss:0.56889796;  eval acc:0.8284129055168621\n",
      "validation loss decreases...\n",
      "current epoch:24;  train loss:0.2539525;  train acc:0.9333983271539547;  eval loss:0.6435825;  eval acc:0.8153477536198679\n",
      "1epochs of increasing val loss\n",
      "current epoch:25;  train loss:0.23795323;  train acc:0.9386383849752825;  eval loss:0.6249667;  eval acc:0.8130357232862905\n",
      "2epochs of increasing val loss\n",
      "current epoch:26;  train loss:0.22208081;  train acc:0.9412316494526838;  eval loss:0.57226664;  eval acc:0.8203254902859238\n",
      "3epochs of increasing val loss\n",
      "current epoch:27;  train loss:0.20033138;  train acc:0.9500538709392655;  eval loss:0.6500598;  eval acc:0.7905330312958211\n",
      "4epochs of increasing val loss\n",
      "current epoch:28;  train loss:0.19312815;  train acc:0.9513067289018363;  eval loss:0.5626692;  eval acc:0.8284514582569649\n",
      "validation loss decreases...\n",
      "current epoch:29;  train loss:0.20216708;  train acc:0.948819060072387;  eval loss:0.79099023;  eval acc:0.7410637371700879\n",
      "1epochs of increasing val loss\n",
      "current epoch:30;  train loss:0.18720566;  train acc:0.95211115708863;  eval loss:0.62116563;  eval acc:0.8259052705736804\n",
      "2epochs of increasing val loss\n",
      "current epoch:31;  train loss:0.1681837;  train acc:0.9578517280190678;  eval loss:0.6172376;  eval acc:0.8149086326979472\n",
      "3epochs of increasing val loss\n",
      "current epoch:32;  train loss:0.15199256;  train acc:0.9635862243997176;  eval loss:0.56049573;  eval acc:0.820086939836877\n",
      "validation loss decreases...\n",
      "current epoch:33;  train loss:0.13118263;  train acc:0.9704352048022601;  eval loss:0.53957844;  eval acc:0.8417439745234603\n",
      "validation loss decreases...\n",
      "current epoch:34;  train loss:0.12722392;  train acc:0.9708644729872882;  eval loss:0.6052367;  eval acc:0.8133225691898827\n",
      "1epochs of increasing val loss\n",
      "current epoch:35;  train loss:0.12511885;  train acc:0.9711502802789548;  eval loss:0.5869275;  eval acc:0.8302121689424488\n",
      "2epochs of increasing val loss\n",
      "current epoch:36;  train loss:0.12176702;  train acc:0.9714284516242938;  eval loss:0.6932237;  eval acc:0.803138517228739\n",
      "3epochs of increasing val loss\n",
      "current epoch:37;  train loss:0.111744724;  train acc:0.9745505715925141;  eval loss:0.5928695;  eval acc:0.8351061331561582\n",
      "4epochs of increasing val loss\n",
      "current epoch:38;  train loss:0.10083764;  train acc:0.9771573479431496;  eval loss:0.6414747;  eval acc:0.8194796153317448\n",
      "5epochs of increasing val loss\n",
      "current epoch:39;  train loss:0.09278625;  train acc:0.9796441615907486;  eval loss:0.67125416;  eval acc:0.8038166983596042\n",
      "6epochs of increasing val loss\n",
      "current epoch:40;  train loss:0.100272834;  train acc:0.9768070433880651;  eval loss:0.6093336;  eval acc:0.8250469952804252\n",
      "7epochs of increasing val loss\n",
      "current epoch:41;  train loss:0.08713779;  train acc:0.9808691902807203;  eval loss:0.62401706;  eval acc:0.8299710009622434\n",
      "8epochs of increasing val loss\n",
      "current epoch:42;  train loss:0.0856897;  train acc:0.9804571526306498;  eval loss:0.6855395;  eval acc:0.8202910900843109\n",
      "9epochs of increasing val loss\n",
      "current epoch:43;  train loss:0.08261115;  train acc:0.9818662992143362;  eval loss:0.5582082;  eval acc:0.842088818502566\n",
      "10epochs of increasing val loss\n",
      "Out of patience, stopping training... \n",
      "[1.5578383, 1.3150523, 1.166938, 1.0126544, 0.9453277, 0.8912663, 0.87136817, 0.8330962, 0.81455106, 0.78165334, 0.7942192, 0.75000113, 0.7172096, 0.6758148, 0.60182005, 0.566704, 0.4852452, 0.39829087, 0.36112866, 0.31782773, 0.29568082, 0.2762448, 0.2704338, 0.27896076, 0.2539525, 0.23795323, 0.22208081, 0.20033138, 0.19312815, 0.20216708, 0.18720566, 0.1681837, 0.15199256, 0.13118263, 0.12722392, 0.12511885, 0.12176702, 0.111744724, 0.10083764, 0.09278625, 0.100272834, 0.08713779, 0.0856897, 0.08261115]\n",
      "[1.5316556, 1.3684666, 1.2843099, 1.2919371, 1.3342907, 1.3511481, 1.208771, 1.1639537, 0.8788954, 0.87362885, 1.2693404, 1.0207355, 0.8032504, 0.79074556, 0.79860187, 0.8859371, 0.6880293, 0.7118574, 0.6100347, 0.6186722, 0.67543215, 0.6907039, 0.6004376, 0.56889796, 0.6435825, 0.6249667, 0.57226664, 0.6500598, 0.5626692, 0.79099023, 0.62116563, 0.6172376, 0.56049573, 0.53957844, 0.6052367, 0.5869275, 0.6932237, 0.5928695, 0.6414747, 0.67125416, 0.6093336, 0.62401706, 0.6855395, 0.5582082]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end!!\n"
     ]
    }
   ],
   "source": [
    "class MyTrainData(data.Dataset):\n",
    "    def __init__(self, image, label):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "        print(len(self.image))\n",
    "    def __getitem__(self,index):\n",
    "        img, lb = self.image[index],self.label[index]\n",
    "        return img,lb\n",
    "#获取loader\n",
    "def getloader(image,label,batch_size = opt.batch_size, shuffle = False):\n",
    "    label = label.astype(np.int64)\n",
    "    dataset = MyTrainData(image,label)\n",
    "    loader = data.DataLoader(dataset,batch_size = batch_size, shuffle = shuffle)\n",
    "    return loader\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by x every y epochs\"\"\"\n",
    "    lr = opt.lr * (0.5 ** (epoch // 20))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def CrossEntropy2d(input, target, weight=None, size_average=True):\n",
    "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
    "    dim = input.dim()\n",
    "    if dim == 2:\n",
    "        return F.cross_entropy(input, target, weight, size_average)\n",
    "    elif dim == 4:\n",
    "        output = input.view(input.size(0), input.size(1), -1)\n",
    "        output = torch.transpose(output, 1, 2).contiguous()\n",
    "        output = output.view(-1, output.size(2))\n",
    "        target = target.view(-1)\n",
    "        return F.cross_entropy(output, target, weight, size_average)\n",
    "    else:\n",
    "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
    "\n",
    "def get_loss():\n",
    "    return CrossEntropy2d\n",
    "        \n",
    "\n",
    "def train(model, train_loader,eval_loader, myloss, optimizer,epoches):\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    train_acc = []\n",
    "    eval_acc = []\n",
    "    p = 0\n",
    "    patience = 10\n",
    "    valid_loss_min = np.Inf\n",
    "    stop = False\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        \n",
    "        adjust_learning_rate(optimizer,epoch)\n",
    "        train_losses_temp = []\n",
    "        eval_losses_temp = []\n",
    "        train_acc_temp = []\n",
    "        eval_acc_temp = []\n",
    "        model.train()        \n",
    "\n",
    "        for i, [images,labels] in enumerate(train_loader):\n",
    "\n",
    "            images = Variable(images.type(torch.FloatTensor)).cuda()\n",
    "            labels = Variable(labels.type(torch.LongTensor)).cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(images)\n",
    "            pred = np.expand_dims(np.argmax(output.data.cpu().numpy(), axis=1),axis=1)\n",
    "\n",
    "            loss = myloss(output,labels)\n",
    "            train_losses_temp.append(loss.data.cpu().numpy())\n",
    "\n",
    "            acc = accuracy_score(labels.data.cpu().numpy().flatten(),pred.flatten())\n",
    "            train_acc_temp.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del images\n",
    "            del labels\n",
    "\n",
    "        train_losses.append(np.mean(train_losses_temp))\n",
    "        train_acc.append(np.mean(train_acc_temp))\n",
    "\n",
    "        model.eval()\n",
    "        for i, [images,labels] in enumerate(eval_loader):\n",
    "\n",
    "            images = Variable(images.type(torch.FloatTensor)).cuda()\n",
    "            labels = Variable(labels.type(torch.LongTensor)).cuda()\n",
    "\n",
    "            output = model(images)\n",
    "            pred = np.expand_dims(np.argmax(output.data.cpu().numpy(), axis=1),axis=1)#pred shape: (batch_size,1,patch_size,patch_size)\n",
    "\n",
    "            loss = myloss(output,labels)\n",
    "            eval_losses_temp.append(loss.data.cpu().numpy())\n",
    "\n",
    "            acc = accuracy_score(labels.data.cpu().numpy().flatten(),pred.flatten())\n",
    "            eval_acc_temp.append(acc)\n",
    "            del images\n",
    "            del labels\n",
    "        eval_losses.append(np.mean(eval_losses_temp))\n",
    "        eval_acc.append(np.mean(eval_acc_temp))\n",
    "        print(\"current epoch:\"+str(epoch)+\";  train loss:\"+str(train_losses[epoch])\\\n",
    "              +\";  train acc:\"+str(train_acc[epoch])+\";  eval loss:\"+str(eval_losses[epoch])+\";  eval acc:\"+str(eval_acc[epoch]))\n",
    "\n",
    "        if eval_losses[epoch] <= valid_loss_min:\n",
    "            print(\"validation loss decreases...\") \n",
    "            torch.save(model, 'temp.pkl') \n",
    "            valid_loss_min = eval_losses[epoch]\n",
    "            p = 0\n",
    "        if eval_losses[epoch] > valid_loss_min:\n",
    "            p += 1\n",
    "            print(str(p)+\"epochs of increasing val loss\")\n",
    "            if p >= patience:\n",
    "                print(\"Out of patience, stopping training... \")\n",
    "                stop = True\n",
    "        if stop:\n",
    "            break\n",
    "    print(train_losses)\n",
    "    print(eval_losses)\n",
    "    plt.plot(train_losses,'b-')\n",
    "    plt.plot(eval_losses, 'g-')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "\n",
    "    print(\"start!!\")\n",
    "    model = segnet(n_classes=opt.num_class, in_channels=3, is_unpooling=True).cuda()\n",
    "    \n",
    "    debug_mode = False \n",
    "    print_model = False \n",
    "    \n",
    "    if debug_mode == False:\n",
    "        vgg16net = models.vgg16(pretrained=True).cuda()\n",
    "        model.init_vgg16_params(vgg16net)    \n",
    "        if print_model == True:\n",
    "            print(model)\n",
    "\n",
    "\n",
    "    data1 = np.load('train_data_x_patch_'+str(opt.patch_size)+'.npy').astype(np.float32)\n",
    "    data_train = np.concatenate((data1,data1,data1),axis =1)\n",
    "    del data1\n",
    "    label_train = np.load('train_data_y_patch_'+str(opt.patch_size)+'_numerical.npy')\n",
    "    data1 = np.load('test_data_x_patch_'+str(opt.patch_size)+'.npy').astype(np.float32)\n",
    "    data_test = np.concatenate((data1,data1,data1),axis =1)\n",
    "    del data1\n",
    "    label_test = np.load('test_data_y_patch_'+str(opt.patch_size)+'_numerical.npy')\n",
    "    \n",
    "\n",
    "    \n",
    "    X_, data_eval, y_, label_eval = train_test_split(data_test,label_test,test_size=0.1,random_state=11)\n",
    "    del X_, y_, data_test, label_test\n",
    "\n",
    "    \n",
    "    myloss= get_loss()\n",
    "    myoptimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),lr = opt.lr,weight_decay = opt.weight_decay, momentum = opt.momentum)\n",
    "    train_loader = getloader(data_train,label_train, batch_size = opt.batch_size, shuffle = True)\n",
    "    eval_loader = getloader(data_eval,label_eval, batch_size = opt.batch_size, shuffle = True)\n",
    "    for epoch in [opt.epoch]:\n",
    "        print('total epoch num is %d'%epoch)\n",
    "        train(model, train_loader, eval_loader, myloss, myoptimizer, epoch)\n",
    "    #torch.save(model, 'temp.pkl') \n",
    "    print(\"end!!\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51238, 3, 32, 32)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "opt = config()\n",
    "\n",
    "data1 = np.load('test_data_x_patch_'+str(opt.patch_size)+'.npy').astype(np.float32)\n",
    "data_test = np.concatenate((data1,data1,data1),axis =1)\n",
    "del data1\n",
    "print(data_test.shape)\n",
    "\n",
    "\n",
    "model = torch.load('temp.pkl')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "data_temp = np.zeros((1,3,opt.patch_size,opt.patch_size)).astype(np.float32)\n",
    "test_out = np.zeros((data_test.shape[0],5,opt.patch_size,opt.patch_size))\n",
    "\n",
    "\n",
    "for i in range(data_test.shape[0]):\n",
    "    data_temp[0,:,:,:] = data_test[i,:,:,:]\n",
    "    data_temp_v = Variable(torch.from_numpy(data_temp)).cuda()\n",
    "    temp_out = model(data_temp_v)\n",
    "    temp_out_a = temp_out.cpu().data.numpy()\n",
    "    test_out[i,:,:,:] = temp_out_a\n",
    "    del data_temp_v\n",
    "    del temp_out\n",
    "    del temp_out_a\n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "del data_temp    \n",
    "\n",
    "test_result = np.argmax(test_out,axis = 1)\n",
    "np.save('test_result_'+str(opt.patch_size),test_result)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3734306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       river     0.6662    0.8165    0.7337   6536490\n",
      "       urban     0.6788    0.5361    0.5991   3734306\n",
      "    farmland     0.6849    0.6567    0.6705   3168694\n",
      "  background     0.8801    0.8628    0.8714  29677404\n",
      "   non-image     0.9845    0.9872    0.9858   9350818\n",
      "\n",
      "    accuracy                         0.8435  52467712\n",
      "   macro avg     0.7789    0.7718    0.7721  52467712\n",
      "weighted avg     0.8460    0.8435    0.8431  52467712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result = np.load('test_result_'+str(opt.patch_size)+\".npy\").astype(np.int32)\n",
    "test_result.resize((test_result.shape[0]*test_result.shape[1]*test_result.shape[2]))\n",
    "test_label = np.load('test_data_y_patch_'+str(opt.patch_size)+'_numerical.npy').astype(np.int32).squeeze()\n",
    "test_label.resize((test_label.shape[0]*test_label.shape[1]*test_label.shape[2]))\n",
    "print(np.sum(test_label==1))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_name = [ 'river','urban','farmland','background','non-image']\n",
    "\n",
    "print(classification_report(test_label,test_result,target_names = target_name,digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
